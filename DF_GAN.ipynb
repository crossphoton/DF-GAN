{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DF-GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zDZFUGz9M06T",
        "aW-TSaCMijY_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlOKRIDLJmqD",
        "outputId": "d4bb2b09-902d-4886-ba8a-7018562f1a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bc6386d60349>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnvidia\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msmi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'nvidia' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjLkK-YOIeML"
      },
      "source": [
        "### Clear everything\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RebF2c14IcIw"
      },
      "source": [
        "!rm -rf DF-GAN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPR4obYOMXeR"
      },
      "source": [
        "### Get Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Doc01JgNHfAC"
      },
      "source": [
        "pick_me = \"crossphoton\"  #@param ['crossphoton', 'tobran']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL_X9y4tMUtf",
        "outputId": "7c332a68-21db-4a81-94cb-c065c7c1369e"
      },
      "source": [
        "if pick_me == \"crossphoton\":\n",
        "  !git clone https://github.com/crossphoton/DF-GAN.git\n",
        "else:\n",
        "  !git clone https://github.com/tobran/DF-GAN.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DF-GAN'...\n",
            "remote: Enumerating objects: 129, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 129 (delta 4), reused 8 (delta 1), pack-reused 112\u001b[K\n",
            "Receiving objects: 100% (129/129), 1.98 MiB | 11.83 MiB/s, done.\n",
            "Resolving deltas: 100% (43/43), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDZFUGz9M06T"
      },
      "source": [
        "### Get data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYhv6A6ZRboW"
      },
      "source": [
        "#### Get Metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N84vQjIg5b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45e19f3b-5022-40c0-b3f5-e3f2c7de9264"
      },
      "source": [
        "%%shell\n",
        "# Clean workspace\n",
        "\n",
        "cd DF-GAN/data\n",
        "rm -rf coco/ birds/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnAvNEjtM5QM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "945a63f5-0060-4bb8-8aea-d6f56c1311f8"
      },
      "source": [
        "%%shell\n",
        "\n",
        "cd DF-GAN/data\n",
        "\n",
        "# birds\n",
        "gdown -O temp.zip https://drive.google.com/uc?id=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ\n",
        "unzip temp.zip > /dev/null\n",
        "rm temp.zip\n",
        "rm -rf __MACOSX/\n",
        "\n",
        "# coco\n",
        "gdown -O temp.zip https://drive.google.com/uc?id=1rSnbIGNDGZeHlsUlLdahj0RJ9oo6lgH9\n",
        "unzip temp.zip > /dev/null\n",
        "rm temp.zip\n",
        "rm -rf __MACOSX/\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ\n",
            "To: /content/DF-GAN/data/temp.zip\n",
            "6.49MB [00:00, 57.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rSnbIGNDGZeHlsUlLdahj0RJ9oo6lgH9\n",
            "To: /content/DF-GAN/data/temp.zip\n",
            "33.3MB [00:00, 91.3MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAaAevWMbkPS"
      },
      "source": [
        "#### Get Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9WliyMCUw93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85d9680b-61ac-4388-99ad-56aa84ca1ced"
      },
      "source": [
        "%%shell\n",
        "# birds\n",
        "\n",
        "cd DF-GAN/data/birds/\n",
        "gdown -O temp.tgz --id 1hbzc_P1FuxMkcabkgn9ZKinBwW683j45\n",
        "tar -xvzf temp.tgz > /dev/null\n",
        "rm temp.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hbzc_P1FuxMkcabkgn9ZKinBwW683j45\n",
            "To: /content/DF-GAN/data/birds/temp.tgz\n",
            "1.15GB [00:07, 146MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EY6TPtMcHUz",
        "outputId": "e3feb795-b149-4349-8dde-30c6ee12b82c"
      },
      "source": [
        "%%shell\n",
        "# coco\n",
        "\n",
        "cd DF-GAN/data/coco/\n",
        "\n",
        "wget http://images.cocodataset.org/zips/train2017.zip\n",
        "wget http://images.cocodataset.org/zips/val2017.zip\n",
        "wget http://images.cocodataset.org/zips/test2017.zip\n",
        "wget http://images.cocodataset.org/zips/unlabeled2017.zip\n",
        "\n",
        "rm -rf train2017 val2017 test2017 unlabeled2017\n",
        "\n",
        "unzip train2017.zip > /dev/null\n",
        "rm train2017.zip\n",
        "\n",
        "unzip val2017.zip > /dev/null\n",
        "rm val2017.zip\n",
        "\n",
        "unzip test2017.zip > /dev/null\n",
        "rm test2017.zip\n",
        "\n",
        "unzip unlabeled2017.zip > /dev/null\n",
        "rm unlabeled2017.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open train2017.zip, train2017.zip.zip or train2017.zip.ZIP.\n",
            "rm: cannot remove 'train2017.zip': No such file or directory\n",
            "unzip:  cannot find or open val2017.zip, val2017.zip.zip or val2017.zip.ZIP.\n",
            "rm: cannot remove 'val2017.zip': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foBTdK0zd4Mm"
      },
      "source": [
        "#### Get Encoders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvkXK79cd6HU",
        "outputId": "644c2c13-fe5f-4cd3-af70-2249f562e72a"
      },
      "source": [
        "%%shell\n",
        "\n",
        "rm -rf DF-GAN/DAMSMencoders/*\n",
        "\n",
        "cd DF-GAN/DAMSMencoders/\n",
        "mkdir -p bird\n",
        "mkdir -p coco\n",
        "\n",
        "gdown -O bird/temp.zip --id 1GNUKjVeyWYBJ8hEU-yrfYQpDOkxEyP3V\n",
        "gdown -O coco/temp.zip --id 1GNUKjVeyWYBJ8hEU-yrfYQpDOkxEyP3V\n",
        "\n",
        "unzip bird/temp.zip -d bird\n",
        "mv bird/bird bird/inception\n",
        "unzip coco/temp.zip -d coco\n",
        "mv coco/bird coco/inception\n",
        "\n",
        "rm bird/temp.zip coco/temp.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1GNUKjVeyWYBJ8hEU-yrfYQpDOkxEyP3V\n",
            "To: /content/DF-GAN/DAMSMencoders/bird/temp.zip\n",
            "91.4MB [00:00, 176MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1GNUKjVeyWYBJ8hEU-yrfYQpDOkxEyP3V\n",
            "To: /content/DF-GAN/DAMSMencoders/coco/temp.zip\n",
            "91.4MB [00:00, 172MB/s]\n",
            "Archive:  bird/temp.zip\n",
            "   creating: bird/bird/\n",
            "  inflating: bird/bird/image_encoder200.pth  \n",
            "  inflating: bird/bird/text_encoder200.pth  \n",
            "Archive:  coco/temp.zip\n",
            "   creating: coco/bird/\n",
            "  inflating: coco/bird/image_encoder200.pth  \n",
            "  inflating: coco/bird/text_encoder200.pth  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW-TSaCMijY_"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blr2GqzuiniU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ebffcaa2-3f86-4456-f3d7-3fb9be2c48c2"
      },
      "source": [
        "%%shell\n",
        "# birds\n",
        "\n",
        "cd DF-GAN/code\n",
        "\n",
        "python3 main.py --cfg cfg/bird.yml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using config:\n",
            "{'B_VALIDATION': False,\n",
            " 'CONFIG_NAME': 'bird',\n",
            " 'CUDA': True,\n",
            " 'DATASET_NAME': 'birds',\n",
            " 'DATA_DIR': '../data/birds',\n",
            " 'GAN': {'B_ATTENTION': True,\n",
            "         'B_DCGAN': True,\n",
            "         'CONDITION_DIM': 100,\n",
            "         'DF_DIM': 64,\n",
            "         'GF_DIM': 128,\n",
            "         'R_NUM': 2,\n",
            "         'Z_DIM': 100},\n",
            " 'GPU_ID': 0,\n",
            " 'RNN_TYPE': 'LSTM',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10,\n",
            "          'DAMSM_NAME': '../DAMSMencoders/bird/inception/text_encoder200.pth',\n",
            "          'EMBEDDING_DIM': 256,\n",
            "          'WORDS_NUM': 18},\n",
            " 'TRAIN': {'BATCH_SIZE': 24,\n",
            "           'B_NET_D': True,\n",
            "           'DISCRIMINATOR_LR': 0.0002,\n",
            "           'ENCODER_LR': 0.0002,\n",
            "           'FLAG': True,\n",
            "           'GENERATOR_LR': 0.0002,\n",
            "           'MAX_EPOCH': 601,\n",
            "           'NET_E': '',\n",
            "           'NET_G': '../test',\n",
            "           'NF': 32,\n",
            "           'RNN_GRAD_CLIP': 0.25,\n",
            "           'SMOOTH': {'GAMMA1': 5.0,\n",
            "                      'GAMMA2': 5.0,\n",
            "                      'GAMMA3': 10.0,\n",
            "                      'LAMBDA': 1.0},\n",
            "           'SNAPSHOT_INTERVAL': 2000},\n",
            " 'TREE': {'BASE_SIZE': 256, 'BRANCH_NUM': 1},\n",
            " 'WORKERS': 1,\n",
            " 'loss': 'hinge'}\n",
            "seed now is :  100\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions.pickle\n",
            "5450 10\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Starting........\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[1/601][0/368] Loss_D: 2.000 Loss_G -0.019\n",
            "[1/601][1/368] Loss_D: 1.992 Loss_G -0.007\n",
            "[1/601][2/368] Loss_D: 1.969 Loss_G -0.086\n",
            "[1/601][3/368] Loss_D: 1.908 Loss_G -0.200\n",
            "[1/601][4/368] Loss_D: 1.846 Loss_G 1.037\n",
            "[1/601][5/368] Loss_D: 1.896 Loss_G 0.127\n",
            "[1/601][6/368] Loss_D: 1.809 Loss_G 0.180\n",
            "[1/601][7/368] Loss_D: 1.711 Loss_G 1.080\n",
            "[1/601][8/368] Loss_D: 1.553 Loss_G -0.050\n",
            "[1/601][9/368] Loss_D: 2.004 Loss_G 1.490\n",
            "[1/601][10/368] Loss_D: 1.899 Loss_G 0.125\n",
            "[1/601][11/368] Loss_D: 1.620 Loss_G 0.794\n",
            "[1/601][12/368] Loss_D: 1.582 Loss_G 0.585\n",
            "[1/601][13/368] Loss_D: 1.540 Loss_G 1.206\n",
            "[1/601][14/368] Loss_D: 1.480 Loss_G 0.596\n",
            "[1/601][15/368] Loss_D: 1.775 Loss_G 1.647\n",
            "[1/601][16/368] Loss_D: 1.951 Loss_G 0.385\n",
            "[1/601][17/368] Loss_D: 1.538 Loss_G 0.794\n",
            "[1/601][18/368] Loss_D: 1.641 Loss_G 0.710\n",
            "[1/601][19/368] Loss_D: 1.674 Loss_G 1.136\n",
            "[1/601][20/368] Loss_D: 1.626 Loss_G 0.375\n",
            "[1/601][21/368] Loss_D: 2.277 Loss_G 1.242\n",
            "[1/601][22/368] Loss_D: 1.815 Loss_G 0.366\n",
            "[1/601][23/368] Loss_D: 1.727 Loss_G 1.007\n",
            "[1/601][24/368] Loss_D: 1.499 Loss_G 1.116\n",
            "[1/601][25/368] Loss_D: 1.392 Loss_G 0.961\n",
            "[1/601][26/368] Loss_D: 1.395 Loss_G 1.424\n",
            "[1/601][27/368] Loss_D: 1.318 Loss_G 0.999\n",
            "[1/601][28/368] Loss_D: 1.391 Loss_G 2.253\n",
            "[1/601][29/368] Loss_D: 1.471 Loss_G 0.138\n",
            "[1/601][30/368] Loss_D: 2.150 Loss_G 1.295\n",
            "[1/601][31/368] Loss_D: 1.542 Loss_G 0.939\n",
            "[1/601][32/368] Loss_D: 1.329 Loss_G 1.731\n",
            "[1/601][33/368] Loss_D: 1.373 Loss_G 0.953\n",
            "[1/601][34/368] Loss_D: 1.214 Loss_G 2.381\n",
            "[1/601][35/368] Loss_D: 1.315 Loss_G 1.364\n",
            "[1/601][36/368] Loss_D: 1.316 Loss_G 1.423\n",
            "[1/601][37/368] Loss_D: 1.270 Loss_G 0.898\n",
            "[1/601][38/368] Loss_D: 1.532 Loss_G 3.032\n",
            "[1/601][39/368] Loss_D: 1.443 Loss_G 1.740\n",
            "[1/601][40/368] Loss_D: 1.177 Loss_G 1.192\n",
            "[1/601][41/368] Loss_D: 1.231 Loss_G 2.648\n",
            "[1/601][42/368] Loss_D: 1.209 Loss_G 1.514\n",
            "[1/601][43/368] Loss_D: 1.179 Loss_G 2.094\n",
            "[1/601][44/368] Loss_D: 1.190 Loss_G 1.284\n",
            "[1/601][45/368] Loss_D: 1.161 Loss_G 2.951\n",
            "[1/601][46/368] Loss_D: 1.174 Loss_G 1.723\n",
            "[1/601][47/368] Loss_D: 1.155 Loss_G 1.067\n",
            "[1/601][48/368] Loss_D: 1.255 Loss_G 4.424\n",
            "[1/601][49/368] Loss_D: 1.413 Loss_G 2.994\n",
            "[1/601][50/368] Loss_D: 1.397 Loss_G 1.521\n",
            "[1/601][51/368] Loss_D: 1.189 Loss_G 2.292\n",
            "[1/601][52/368] Loss_D: 1.148 Loss_G 1.614\n",
            "[1/601][53/368] Loss_D: 1.219 Loss_G 4.738\n",
            "[1/601][54/368] Loss_D: 1.682 Loss_G 0.193\n",
            "[1/601][55/368] Loss_D: 2.061 Loss_G 0.543\n",
            "[1/601][56/368] Loss_D: 1.770 Loss_G 1.337\n",
            "[1/601][57/368] Loss_D: 1.519 Loss_G 2.775\n",
            "[1/601][58/368] Loss_D: 1.673 Loss_G 0.739\n",
            "[1/601][59/368] Loss_D: 1.421 Loss_G 2.272\n",
            "[1/601][60/368] Loss_D: 1.329 Loss_G 1.393\n",
            "[1/601][61/368] Loss_D: 1.285 Loss_G 1.136\n",
            "[1/601][62/368] Loss_D: 1.250 Loss_G 1.350\n",
            "[1/601][63/368] Loss_D: 1.180 Loss_G 1.108\n",
            "[1/601][64/368] Loss_D: 1.288 Loss_G 3.309\n",
            "[1/601][65/368] Loss_D: 1.506 Loss_G 1.216\n",
            "[1/601][66/368] Loss_D: 1.221 Loss_G 1.641\n",
            "[1/601][67/368] Loss_D: 1.161 Loss_G 1.327\n",
            "[1/601][68/368] Loss_D: 1.405 Loss_G 1.419\n",
            "[1/601][69/368] Loss_D: 1.262 Loss_G 0.842\n",
            "[1/601][70/368] Loss_D: 1.233 Loss_G 2.548\n",
            "[1/601][71/368] Loss_D: 1.370 Loss_G 0.784\n",
            "[1/601][72/368] Loss_D: 1.716 Loss_G 2.760\n",
            "[1/601][73/368] Loss_D: 1.327 Loss_G 1.595\n",
            "[1/601][74/368] Loss_D: 1.179 Loss_G 1.067\n",
            "[1/601][75/368] Loss_D: 1.167 Loss_G 2.385\n",
            "[1/601][76/368] Loss_D: 1.201 Loss_G 1.855\n",
            "[1/601][77/368] Loss_D: 1.205 Loss_G 1.460\n",
            "[1/601][78/368] Loss_D: 1.122 Loss_G 1.256\n",
            "[1/601][79/368] Loss_D: 1.405 Loss_G 3.718\n",
            "[1/601][80/368] Loss_D: 1.496 Loss_G 1.016\n",
            "[1/601][81/368] Loss_D: 1.240 Loss_G 2.295\n",
            "[1/601][82/368] Loss_D: 1.198 Loss_G 1.442\n",
            "[1/601][83/368] Loss_D: 1.451 Loss_G 2.982\n",
            "[1/601][84/368] Loss_D: 1.469 Loss_G 1.480\n",
            "[1/601][85/368] Loss_D: 1.316 Loss_G 1.799\n",
            "[1/601][86/368] Loss_D: 1.201 Loss_G 0.488\n",
            "[1/601][87/368] Loss_D: 1.689 Loss_G 2.627\n",
            "[1/601][88/368] Loss_D: 1.251 Loss_G 1.785\n",
            "[1/601][89/368] Loss_D: 1.239 Loss_G 1.813\n",
            "[1/601][90/368] Loss_D: 1.177 Loss_G 1.312\n",
            "[1/601][91/368] Loss_D: 1.253 Loss_G 1.505\n",
            "[1/601][92/368] Loss_D: 1.110 Loss_G 1.129\n",
            "[1/601][93/368] Loss_D: 1.148 Loss_G 1.519\n",
            "[1/601][94/368] Loss_D: 1.118 Loss_G 1.265\n",
            "[1/601][95/368] Loss_D: 1.275 Loss_G 1.745\n",
            "[1/601][96/368] Loss_D: 1.356 Loss_G 1.121\n",
            "[1/601][97/368] Loss_D: 1.217 Loss_G 1.532\n",
            "[1/601][98/368] Loss_D: 1.293 Loss_G 3.592\n",
            "[1/601][99/368] Loss_D: 1.699 Loss_G 0.606\n",
            "[1/601][100/368] Loss_D: 1.291 Loss_G 2.765\n",
            "[1/601][101/368] Loss_D: 1.533 Loss_G 1.412\n",
            "[1/601][102/368] Loss_D: 1.216 Loss_G 2.224\n",
            "[1/601][103/368] Loss_D: 1.457 Loss_G 0.597\n",
            "[1/601][104/368] Loss_D: 1.676 Loss_G 2.580\n",
            "[1/601][105/368] Loss_D: 1.307 Loss_G 1.198\n",
            "[1/601][106/368] Loss_D: 1.353 Loss_G 2.848\n",
            "[1/601][107/368] Loss_D: 1.203 Loss_G 2.124\n",
            "[1/601][108/368] Loss_D: 1.211 Loss_G 1.684\n",
            "[1/601][109/368] Loss_D: 1.432 Loss_G 4.263\n",
            "[1/601][110/368] Loss_D: 1.647 Loss_G 0.812\n",
            "[1/601][111/368] Loss_D: 1.438 Loss_G 3.314\n",
            "[1/601][112/368] Loss_D: 1.435 Loss_G 1.398\n",
            "[1/601][113/368] Loss_D: 1.207 Loss_G 1.584\n",
            "[1/601][114/368] Loss_D: 1.129 Loss_G 1.473\n",
            "[1/601][115/368] Loss_D: 1.145 Loss_G 2.774\n",
            "[1/601][116/368] Loss_D: 1.179 Loss_G 2.205\n",
            "[1/601][117/368] Loss_D: 1.143 Loss_G 1.801\n",
            "[1/601][118/368] Loss_D: 1.208 Loss_G 1.424\n",
            "[1/601][119/368] Loss_D: 1.220 Loss_G 2.265\n",
            "[1/601][120/368] Loss_D: 1.283 Loss_G 1.532\n",
            "[1/601][121/368] Loss_D: 1.359 Loss_G 3.650\n",
            "[1/601][122/368] Loss_D: 1.834 Loss_G 0.045\n",
            "[1/601][123/368] Loss_D: 1.626 Loss_G 1.433\n",
            "[1/601][124/368] Loss_D: 1.231 Loss_G 1.469\n",
            "[1/601][125/368] Loss_D: 1.361 Loss_G 1.000\n",
            "[1/601][126/368] Loss_D: 1.226 Loss_G 2.062\n",
            "[1/601][127/368] Loss_D: 1.313 Loss_G 0.848\n",
            "[1/601][128/368] Loss_D: 1.409 Loss_G 2.299\n",
            "[1/601][129/368] Loss_D: 1.399 Loss_G 1.040\n",
            "[1/601][130/368] Loss_D: 1.686 Loss_G 1.667\n",
            "[1/601][131/368] Loss_D: 1.411 Loss_G 1.786\n",
            "[1/601][132/368] Loss_D: 1.489 Loss_G 0.138\n",
            "[1/601][133/368] Loss_D: 1.516 Loss_G 2.156\n",
            "[1/601][134/368] Loss_D: 1.657 Loss_G 0.077\n",
            "[1/601][135/368] Loss_D: 1.608 Loss_G 0.896\n",
            "[1/601][136/368] Loss_D: 1.391 Loss_G 1.410\n",
            "[1/601][137/368] Loss_D: 1.624 Loss_G 0.571\n",
            "[1/601][138/368] Loss_D: 1.516 Loss_G 1.693\n",
            "[1/601][139/368] Loss_D: 1.585 Loss_G 0.954\n",
            "[1/601][140/368] Loss_D: 1.452 Loss_G 1.503\n",
            "[1/601][141/368] Loss_D: 1.359 Loss_G 1.197\n",
            "[1/601][142/368] Loss_D: 1.565 Loss_G 0.391\n",
            "[1/601][143/368] Loss_D: 1.578 Loss_G 1.095\n",
            "[1/601][144/368] Loss_D: 1.404 Loss_G 1.710\n",
            "[1/601][145/368] Loss_D: 1.580 Loss_G 0.263\n",
            "[1/601][146/368] Loss_D: 1.646 Loss_G 0.706\n",
            "[1/601][147/368] Loss_D: 1.621 Loss_G 2.025\n",
            "[1/601][148/368] Loss_D: 1.705 Loss_G 0.469\n",
            "[1/601][149/368] Loss_D: 1.537 Loss_G 1.216\n",
            "[1/601][150/368] Loss_D: 1.608 Loss_G 1.386\n",
            "[1/601][151/368] Loss_D: 1.471 Loss_G 0.654\n",
            "[1/601][152/368] Loss_D: 1.596 Loss_G 1.481\n",
            "[1/601][153/368] Loss_D: 1.677 Loss_G 1.075\n",
            "[1/601][154/368] Loss_D: 1.584 Loss_G 1.769\n",
            "[1/601][155/368] Loss_D: 1.785 Loss_G -0.317\n",
            "[1/601][156/368] Loss_D: 1.917 Loss_G 0.292\n",
            "[1/601][157/368] Loss_D: 1.805 Loss_G 0.517\n",
            "[1/601][158/368] Loss_D: 1.681 Loss_G 0.696\n",
            "[1/601][159/368] Loss_D: 1.498 Loss_G 0.933\n",
            "[1/601][160/368] Loss_D: 1.637 Loss_G 0.973\n",
            "[1/601][161/368] Loss_D: 1.531 Loss_G 1.017\n",
            "[1/601][162/368] Loss_D: 1.650 Loss_G 1.009\n",
            "[1/601][163/368] Loss_D: 1.853 Loss_G 0.368\n",
            "[1/601][164/368] Loss_D: 1.763 Loss_G 1.347\n",
            "[1/601][165/368] Loss_D: 1.740 Loss_G 0.422\n",
            "[1/601][166/368] Loss_D: 1.647 Loss_G 1.104\n",
            "[1/601][167/368] Loss_D: 1.910 Loss_G 0.382\n",
            "[1/601][168/368] Loss_D: 1.794 Loss_G 0.788\n",
            "[1/601][169/368] Loss_D: 1.592 Loss_G 0.738\n",
            "[1/601][170/368] Loss_D: 1.599 Loss_G 1.265\n",
            "[1/601][171/368] Loss_D: 1.720 Loss_G -0.141\n",
            "[1/601][172/368] Loss_D: 1.583 Loss_G 0.723\n",
            "[1/601][173/368] Loss_D: 1.733 Loss_G 0.420\n",
            "[1/601][174/368] Loss_D: 1.616 Loss_G 0.775\n",
            "[1/601][175/368] Loss_D: 1.779 Loss_G 0.331\n",
            "[1/601][176/368] Loss_D: 1.645 Loss_G 0.624\n",
            "[1/601][177/368] Loss_D: 1.678 Loss_G 0.356\n",
            "[1/601][178/368] Loss_D: 1.763 Loss_G 0.619\n",
            "[1/601][179/368] Loss_D: 1.639 Loss_G 0.927\n",
            "[1/601][180/368] Loss_D: 1.837 Loss_G 0.933\n",
            "[1/601][181/368] Loss_D: 1.956 Loss_G 0.375\n",
            "[1/601][182/368] Loss_D: 1.662 Loss_G 0.933\n",
            "[1/601][183/368] Loss_D: 1.566 Loss_G 1.073\n",
            "[1/601][184/368] Loss_D: 1.831 Loss_G 0.471\n",
            "[1/601][185/368] Loss_D: 1.688 Loss_G 0.979\n",
            "[1/601][186/368] Loss_D: 1.619 Loss_G 1.169\n",
            "[1/601][187/368] Loss_D: 1.572 Loss_G 1.301\n",
            "[1/601][188/368] Loss_D: 1.785 Loss_G 0.232\n",
            "[1/601][189/368] Loss_D: 1.700 Loss_G 0.900\n",
            "[1/601][190/368] Loss_D: 1.831 Loss_G 0.586\n",
            "[1/601][191/368] Loss_D: 1.756 Loss_G 0.573\n",
            "[1/601][192/368] Loss_D: 1.774 Loss_G 0.895\n",
            "[1/601][193/368] Loss_D: 1.563 Loss_G 0.809\n",
            "[1/601][194/368] Loss_D: 1.526 Loss_G 1.002\n",
            "[1/601][195/368] Loss_D: 1.558 Loss_G 1.016\n",
            "[1/601][196/368] Loss_D: 1.528 Loss_G 1.282\n",
            "[1/601][197/368] Loss_D: 1.612 Loss_G 0.947\n",
            "[1/601][198/368] Loss_D: 1.750 Loss_G 1.081\n",
            "[1/601][199/368] Loss_D: 1.429 Loss_G 0.953\n",
            "[1/601][200/368] Loss_D: 1.428 Loss_G 1.619\n",
            "[1/601][201/368] Loss_D: 1.525 Loss_G 0.868\n",
            "[1/601][202/368] Loss_D: 1.403 Loss_G 1.311\n",
            "[1/601][203/368] Loss_D: 1.850 Loss_G 1.630\n",
            "[1/601][204/368] Loss_D: 1.608 Loss_G 1.213\n",
            "[1/601][205/368] Loss_D: 1.687 Loss_G 0.908\n",
            "[1/601][206/368] Loss_D: 1.516 Loss_G 1.203\n",
            "[1/601][207/368] Loss_D: 1.686 Loss_G 1.524\n",
            "[1/601][208/368] Loss_D: 1.371 Loss_G 0.839\n",
            "[1/601][209/368] Loss_D: 1.464 Loss_G 2.746\n",
            "[1/601][210/368] Loss_D: 1.906 Loss_G 0.639\n",
            "[1/601][211/368] Loss_D: 1.412 Loss_G 1.525\n",
            "[1/601][212/368] Loss_D: 1.304 Loss_G 1.188\n",
            "[1/601][213/368] Loss_D: 1.371 Loss_G 1.148\n",
            "[1/601][214/368] Loss_D: 1.369 Loss_G 1.564\n",
            "[1/601][215/368] Loss_D: 1.382 Loss_G 1.173\n",
            "[1/601][216/368] Loss_D: 1.541 Loss_G 1.141\n",
            "[1/601][217/368] Loss_D: 1.517 Loss_G 2.000\n",
            "[1/601][218/368] Loss_D: 1.570 Loss_G 1.304\n",
            "[1/601][219/368] Loss_D: 1.638 Loss_G 0.127\n",
            "[1/601][220/368] Loss_D: 1.679 Loss_G 0.939\n",
            "[1/601][221/368] Loss_D: 1.474 Loss_G 1.441\n",
            "[1/601][222/368] Loss_D: 1.329 Loss_G 1.915\n",
            "[1/601][223/368] Loss_D: 1.640 Loss_G 0.261\n",
            "[1/601][224/368] Loss_D: 1.546 Loss_G 1.210\n",
            "[1/601][225/368] Loss_D: 1.420 Loss_G 0.983\n",
            "[1/601][226/368] Loss_D: 1.415 Loss_G 1.384\n",
            "[1/601][227/368] Loss_D: 1.454 Loss_G 0.293\n",
            "[1/601][228/368] Loss_D: 1.563 Loss_G 1.357\n",
            "[1/601][229/368] Loss_D: 1.381 Loss_G 1.821\n",
            "[1/601][230/368] Loss_D: 1.371 Loss_G 1.334\n",
            "[1/601][231/368] Loss_D: 1.627 Loss_G 1.138\n",
            "[1/601][232/368] Loss_D: 1.555 Loss_G 1.106\n",
            "[1/601][233/368] Loss_D: 1.486 Loss_G 0.807\n",
            "[1/601][234/368] Loss_D: 1.573 Loss_G 2.030\n",
            "[1/601][235/368] Loss_D: 1.759 Loss_G 2.107\n",
            "[1/601][236/368] Loss_D: 1.628 Loss_G 1.389\n",
            "[1/601][237/368] Loss_D: 1.456 Loss_G 1.681\n",
            "[1/601][238/368] Loss_D: 1.531 Loss_G 0.637\n",
            "[1/601][239/368] Loss_D: 1.743 Loss_G 1.016\n",
            "[1/601][240/368] Loss_D: 1.403 Loss_G 1.719\n",
            "[1/601][241/368] Loss_D: 1.385 Loss_G 1.226\n",
            "[1/601][242/368] Loss_D: 1.363 Loss_G 1.987\n",
            "[1/601][243/368] Loss_D: 1.671 Loss_G 0.379\n",
            "[1/601][244/368] Loss_D: 1.557 Loss_G 1.545\n",
            "[1/601][245/368] Loss_D: 1.516 Loss_G 1.166\n",
            "[1/601][246/368] Loss_D: 1.477 Loss_G 1.077\n",
            "[1/601][247/368] Loss_D: 1.297 Loss_G 1.429\n",
            "[1/601][248/368] Loss_D: 1.530 Loss_G 1.834\n",
            "[1/601][249/368] Loss_D: 1.285 Loss_G 0.891\n",
            "[1/601][250/368] Loss_D: 1.445 Loss_G 1.094\n",
            "[1/601][251/368] Loss_D: 1.597 Loss_G 1.026\n",
            "[1/601][252/368] Loss_D: 1.386 Loss_G 2.286\n",
            "[1/601][253/368] Loss_D: 1.769 Loss_G 0.625\n",
            "[1/601][254/368] Loss_D: 1.477 Loss_G 1.321\n",
            "[1/601][255/368] Loss_D: 1.454 Loss_G 0.985\n",
            "[1/601][256/368] Loss_D: 1.421 Loss_G 1.053\n",
            "[1/601][257/368] Loss_D: 1.297 Loss_G 1.408\n",
            "[1/601][258/368] Loss_D: 1.411 Loss_G 1.940\n",
            "[1/601][259/368] Loss_D: 1.482 Loss_G 0.638\n",
            "[1/601][260/368] Loss_D: 1.310 Loss_G 3.257\n",
            "[1/601][261/368] Loss_D: 1.597 Loss_G 0.417\n",
            "[1/601][262/368] Loss_D: 1.588 Loss_G 1.381\n",
            "[1/601][263/368] Loss_D: 1.492 Loss_G 0.971\n",
            "[1/601][264/368] Loss_D: 1.350 Loss_G 1.679\n",
            "[1/601][265/368] Loss_D: 1.628 Loss_G 1.007\n",
            "[1/601][266/368] Loss_D: 1.468 Loss_G 1.693\n",
            "[1/601][267/368] Loss_D: 1.288 Loss_G 0.560\n",
            "[1/601][268/368] Loss_D: 1.491 Loss_G 1.797\n",
            "[1/601][269/368] Loss_D: 1.519 Loss_G 0.781\n",
            "[1/601][270/368] Loss_D: 1.357 Loss_G 1.582\n",
            "[1/601][271/368] Loss_D: 1.437 Loss_G 1.517\n",
            "[1/601][272/368] Loss_D: 1.433 Loss_G 1.782\n",
            "[1/601][273/368] Loss_D: 1.453 Loss_G 1.051\n",
            "[1/601][274/368] Loss_D: 1.354 Loss_G 1.680\n",
            "[1/601][275/368] Loss_D: 1.433 Loss_G 0.343\n",
            "[1/601][276/368] Loss_D: 1.609 Loss_G 1.650\n",
            "[1/601][277/368] Loss_D: 1.231 Loss_G 1.500\n",
            "[1/601][278/368] Loss_D: 1.340 Loss_G 1.805\n",
            "[1/601][279/368] Loss_D: 1.568 Loss_G 1.248\n",
            "[1/601][280/368] Loss_D: 1.442 Loss_G 1.698\n",
            "[1/601][281/368] Loss_D: 1.498 Loss_G 0.413\n",
            "[1/601][282/368] Loss_D: 1.486 Loss_G 1.693\n",
            "[1/601][283/368] Loss_D: 1.558 Loss_G 0.887\n",
            "[1/601][284/368] Loss_D: 1.251 Loss_G 1.251\n",
            "[1/601][285/368] Loss_D: 1.261 Loss_G 1.544\n",
            "[1/601][286/368] Loss_D: 1.385 Loss_G 0.852\n",
            "[1/601][287/368] Loss_D: 1.333 Loss_G 1.319\n",
            "[1/601][288/368] Loss_D: 1.451 Loss_G 2.073\n",
            "[1/601][289/368] Loss_D: 1.756 Loss_G 1.195\n",
            "[1/601][290/368] Loss_D: 1.352 Loss_G 1.780\n",
            "[1/601][291/368] Loss_D: 1.469 Loss_G 1.830\n",
            "[1/601][292/368] Loss_D: 1.453 Loss_G 0.894\n",
            "[1/601][293/368] Loss_D: 1.456 Loss_G 1.331\n",
            "[1/601][294/368] Loss_D: 1.562 Loss_G 1.002\n",
            "[1/601][295/368] Loss_D: 1.297 Loss_G 2.522\n",
            "[1/601][297/368] Loss_D: 1.482 Loss_G 1.410\n",
            "[1/601][298/368] Loss_D: 1.486 Loss_G 0.809\n",
            "[1/601][299/368] Loss_D: 1.639 Loss_G 0.787\n",
            "[1/601][300/368] Loss_D: 1.418 Loss_G 1.952\n",
            "[1/601][301/368] Loss_D: 1.362 Loss_G 0.456\n",
            "[1/601][302/368] Loss_D: 1.529 Loss_G 1.103\n",
            "[1/601][303/368] Loss_D: 1.344 Loss_G 2.528\n",
            "[1/601][304/368] Loss_D: 1.502 Loss_G 1.576\n",
            "[1/601][306/368] Loss_D: 1.348 Loss_G 0.793\n",
            "[1/601][307/368] Loss_D: 1.317 Loss_G 1.958\n",
            "[1/601][308/368] Loss_D: 1.555 Loss_G 0.774\n",
            "[1/601][309/368] Loss_D: 1.400 Loss_G 1.127\n",
            "[1/601][310/368] Loss_D: 1.393 Loss_G 1.843\n",
            "[1/601][311/368] Loss_D: 1.330 Loss_G 1.626\n",
            "[1/601][312/368] Loss_D: 1.524 Loss_G 0.475\n",
            "[1/601][313/368] Loss_D: 1.496 Loss_G 1.413\n",
            "[1/601][314/368] Loss_D: 1.383 Loss_G 1.856\n",
            "[1/601][315/368] Loss_D: 1.319 Loss_G 0.868\n",
            "[1/601][316/368] Loss_D: 1.436 Loss_G 1.937\n",
            "[1/601][317/368] Loss_D: 1.262 Loss_G 0.422\n",
            "[1/601][318/368] Loss_D: 1.460 Loss_G 2.093\n",
            "[1/601][319/368] Loss_D: 1.358 Loss_G 2.358\n",
            "[1/601][320/368] Loss_D: 1.345 Loss_G 0.970\n",
            "[1/601][321/368] Loss_D: 1.136 Loss_G 2.779\n",
            "[1/601][322/368] Loss_D: 1.668 Loss_G 1.162\n",
            "[1/601][323/368] Loss_D: 1.398 Loss_G 0.945\n",
            "[1/601][324/368] Loss_D: 1.530 Loss_G 2.472\n",
            "[1/601][325/368] Loss_D: 1.389 Loss_G 0.930\n",
            "[1/601][326/368] Loss_D: 1.332 Loss_G 1.398\n",
            "[1/601][327/368] Loss_D: 1.343 Loss_G 2.662\n",
            "[1/601][328/368] Loss_D: 1.211 Loss_G 2.123\n",
            "[1/601][329/368] Loss_D: 1.235 Loss_G 1.586\n",
            "[1/601][330/368] Loss_D: 1.485 Loss_G 1.935\n",
            "[1/601][331/368] Loss_D: 1.446 Loss_G 0.946\n",
            "[1/601][332/368] Loss_D: 1.384 Loss_G 1.499\n",
            "[1/601][333/368] Loss_D: 1.327 Loss_G 1.174\n",
            "[1/601][334/368] Loss_D: 1.496 Loss_G 1.645\n",
            "[1/601][335/368] Loss_D: 1.389 Loss_G 1.127\n",
            "[1/601][336/368] Loss_D: 1.320 Loss_G 2.039\n",
            "[1/601][337/368] Loss_D: 1.372 Loss_G 1.358\n",
            "[1/601][338/368] Loss_D: 1.278 Loss_G 2.586\n",
            "[1/601][339/368] Loss_D: 1.302 Loss_G 2.792\n",
            "[1/601][340/368] Loss_D: 1.392 Loss_G 1.394\n",
            "[1/601][341/368] Loss_D: 1.388 Loss_G 0.938\n",
            "[1/601][342/368] Loss_D: 1.571 Loss_G 1.402\n",
            "[1/601][343/368] Loss_D: 1.332 Loss_G 1.385\n",
            "[1/601][344/368] Loss_D: 1.290 Loss_G 1.373\n",
            "[1/601][345/368] Loss_D: 1.214 Loss_G 1.892\n",
            "[1/601][346/368] Loss_D: 1.307 Loss_G 1.611\n",
            "[1/601][347/368] Loss_D: 1.433 Loss_G 2.367\n",
            "[1/601][348/368] Loss_D: 1.185 Loss_G 2.523\n",
            "[1/601][349/368] Loss_D: 1.382 Loss_G 0.647\n",
            "[1/601][350/368] Loss_D: 1.330 Loss_G 2.570\n",
            "[1/601][351/368] Loss_D: 1.206 Loss_G 1.680\n",
            "[1/601][352/368] Loss_D: 1.223 Loss_G 2.205\n",
            "[1/601][353/368] Loss_D: 1.304 Loss_G 1.434\n",
            "[1/601][354/368] Loss_D: 1.205 Loss_G 1.861\n",
            "[1/601][355/368] Loss_D: 1.219 Loss_G 1.748\n",
            "[1/601][356/368] Loss_D: 1.297 Loss_G 1.333\n",
            "[1/601][357/368] Loss_D: 1.436 Loss_G 3.268\n",
            "[1/601][358/368] Loss_D: 1.247 Loss_G 1.256\n",
            "[1/601][359/368] Loss_D: 1.335 Loss_G 2.440\n",
            "[1/601][360/368] Loss_D: 1.237 Loss_G 1.091\n",
            "[1/601][361/368] Loss_D: 1.582 Loss_G 2.319\n",
            "[1/601][362/368] Loss_D: 1.481 Loss_G 2.262\n",
            "[1/601][363/368] Loss_D: 1.256 Loss_G 1.571\n",
            "[1/601][364/368] Loss_D: 1.125 Loss_G 2.784\n",
            "[1/601][365/368] Loss_D: 1.442 Loss_G 2.544\n",
            "[1/601][366/368] Loss_D: 1.122 Loss_G 2.138\n",
            "[1/601][367/368] Loss_D: 1.494 Loss_G 1.851\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 277, in <module>\n",
            "    count = train(dataloader,netG,netD,text_encoder,optimizerG,optimizerD, state_epoch,batch_size,device)\n",
            "  File \"main.py\", line 173, in train\n",
            "    normalize=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchvision/utils.py\", line 136, in save_image\n",
            "    im.save(fp, format=format)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 2131, in save\n",
            "    fp = builtins.open(filename, \"w+b\")\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'imgs//fake_samples_epoch_001.png'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-b474bc0a60a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'# birds\\n\\ncd DF-GAN/code\\n\\npython3 main.py --cfg cfg/bird.yml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m       raise subprocess.CalledProcessError(\n\u001b[0;32m--> 139\u001b[0;31m           returncode=self.returncode, cmd=self.args, output=self.output)\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_repr_pretty_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '# birds\n\ncd DF-GAN/code\n\npython3 main.py --cfg cfg/bird.yml' returned non-zero exit status 1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHf2blUujCWA"
      },
      "source": [
        "%%shell\n",
        "# coco\n",
        "\n",
        "cd DF-GAN/code\n",
        "\n",
        "python3 main.py --cfg cfg/coco.yml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EPMo969jaKE"
      },
      "source": [
        "### Pre-trained Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqTmp0BSjgGY"
      },
      "source": [
        "#### Get models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y59ufGP7jeNA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a6b74b6-da4f-4b9e-ac1c-71accbab276a"
      },
      "source": [
        "%%shell\n",
        "\n",
        "cd DF-GAN/code\n",
        "mkdir -p models/bird\n",
        "mkdir models/coco\n",
        "\n",
        "cd models\n",
        "\n",
        "gdown -O bird/netG.pth --id 1svVTyKWj5B1J82rEiZILUS289DsmT6U7\n",
        "gdown -O coco/netG.pth --id 15llod5eTjjdzDTXQroJG_eh2c-GrW9H7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1svVTyKWj5B1J82rEiZILUS289DsmT6U7\n",
            "To: /content/DF-GAN/code/models/bird/netG.pth\n",
            "49.0MB [00:00, 68.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15llod5eTjjdzDTXQroJG_eh2c-GrW9H7\n",
            "To: /content/DF-GAN/code/models/coco/netG.pth\n",
            "49.0MB [00:00, 73.7MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYNdDv21mxjq"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "Change configuration `B_VALIDATION:True`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0F7--q6eNY-"
      },
      "source": [
        "#### Remove `caption.pickle`\n",
        "\n",
        "Force creation of new dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OpcMR0nebip",
        "outputId": "d2e1053b-1f6a-4f64-d686-f71d86930953"
      },
      "source": [
        "%%shell\n",
        "pwd\n",
        "ls\n",
        "cd DF-GAN/data/birds\n",
        "unzip text.zip > /dev/null\n",
        "rm captions.pickle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "DF-GAN\tsample_data\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl36NLg_eouf"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TaCCFd3q1xk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ab940a2-1413-48ef-debd-f2d59ac56f9d"
      },
      "source": [
        "%%shell\n",
        "\n",
        "cd DF-GAN/code\n",
        "\n",
        "# bird\n",
        "time python main.py --cfg cfg/bird.yml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using config:\n",
            "{'B_VALIDATION': True,\n",
            " 'CONFIG_NAME': 'bird',\n",
            " 'CUDA': True,\n",
            " 'DATASET_NAME': 'birds',\n",
            " 'DATA_DIR': '../data/birds',\n",
            " 'GAN': {'B_ATTENTION': True,\n",
            "         'B_DCGAN': True,\n",
            "         'CONDITION_DIM': 100,\n",
            "         'DF_DIM': 64,\n",
            "         'GF_DIM': 128,\n",
            "         'R_NUM': 2,\n",
            "         'Z_DIM': 100},\n",
            " 'GPU_ID': 0,\n",
            " 'RNN_TYPE': 'LSTM',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10,\n",
            "          'DAMSM_NAME': '../DAMSMencoders/bird/inception/text_encoder200.pth',\n",
            "          'EMBEDDING_DIM': 256,\n",
            "          'WORDS_NUM': 18},\n",
            " 'TRAIN': {'BATCH_SIZE': 24,\n",
            "           'B_NET_D': True,\n",
            "           'DISCRIMINATOR_LR': 0.0002,\n",
            "           'ENCODER_LR': 0.0002,\n",
            "           'FLAG': True,\n",
            "           'GENERATOR_LR': 0.0002,\n",
            "           'MAX_EPOCH': 601,\n",
            "           'NET_E': '',\n",
            "           'NET_G': '../test',\n",
            "           'NF': 32,\n",
            "           'RNN_GRAD_CLIP': 0.25,\n",
            "           'SMOOTH': {'GAMMA1': 5.0,\n",
            "                      'GAMMA2': 5.0,\n",
            "                      'GAMMA3': 10.0,\n",
            "                      'LAMBDA': 1.0},\n",
            "           'SNAPSHOT_INTERVAL': 2000},\n",
            " 'TREE': {'BASE_SIZE': 256, 'BRANCH_NUM': 1},\n",
            " 'WORKERS': 1,\n",
            " 'loss': 'hinge'}\n",
            "seed now is :  100\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Save to:  ../data/birds/captions.pickle\n",
            "5450 10\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Starting........\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "step:  0\n",
            "step:  100\n",
            "state_epoch:  0\n",
            "\n",
            "real\t2m24.930s\n",
            "user\t2m40.511s\n",
            "sys\t0m7.333s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3-aUQvErivu"
      },
      "source": [
        "%%shell\n",
        "\n",
        "cd DF-GAN/code\n",
        "\n",
        "# coco\n",
        "python main.py --cfg cfg/coco.yml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTPoLvQ8vUWv"
      },
      "source": [
        "!rm -rf DF-GAN/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bto1KQixrfc"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh_G0rBdL6Ij"
      },
      "source": [
        "text_description = \"\"\n",
        "model=\"bird\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "ZGp_WzAFxqrm",
        "outputId": "fd680814-db13-414c-ca25-22ad2774d8a6"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import time\n",
        "import random\n",
        "import pprint\n",
        "import datetime\n",
        "import dateutil.tz\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "\n",
        "from DF-GAN.code.miscc.config import cfg, cfg_from_file\n",
        "from DF-GAN.code.DAMSM import RNN_ENCODER\n",
        "from DF-GAN.code.model import NetG, NetD\n",
        "from DF-GAN.code.datasets import TextDataset\n",
        "from DF-GAN.code.datasets import prepare_data\n",
        "\n",
        "\n",
        "dir_path = (os.path.abspath(os.path.join(os.path.realpa th(__file__), './.')))\n",
        "sys.path.append(dir_path)\n",
        "\n",
        "UPDATE_INTERVAL = 200\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description='Train a DAMSM network')\n",
        "    parser.add_argument('--cfg', dest='cfg_file',\n",
        "                        help='optional config file',\n",
        "                        default='cfg/bird.yml', type=str)\n",
        "    parser.add_argument('--gpu', dest='gpu_id', type=int, default=0)\n",
        "    parser.add_argument('--data_dir', dest='data_dir', type=str, default='')\n",
        "    parser.add_argument('--manualSeed', type=int, help='manual seed')\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "def runner(text_encoder, netG, data, ):\n",
        "    return None\n",
        "\n",
        "\n",
        "def initialize():\n",
        "    args = parse_args()\n",
        "    if args.cfg_file is not None:\n",
        "        cfg_from_file(args.cfg_file)\n",
        "\n",
        "    if args.gpu_id == -1:\n",
        "        cfg.CUDA = False\n",
        "    else:\n",
        "        cfg.GPU_ID = args.gpu_id\n",
        "\n",
        "    if args.data_dir != '':\n",
        "        cfg.DATA_DIR = args.data_dir\n",
        "    print('Using config:')\n",
        "    pprint.pprint(cfg)\n",
        "\n",
        "    if not cfg.TRAIN.FLAG:\n",
        "        args.manualSeed = 100\n",
        "    elif args.manualSeed is None:\n",
        "        args.manualSeed = 100\n",
        "        #args.manualSeed = random.randint(1, 10000)\n",
        "    print(\"seed now is : \",args.manualSeed)\n",
        "    random.seed(args.manualSeed)\n",
        "    np.random.seed(args.manualSeed)\n",
        "    torch.manual_seed(args.manualSeed)\n",
        "    if cfg.CUDA:\n",
        "        torch.cuda.manual_seed_all(args.manualSeed)\n",
        "\n",
        "    ##########################################################################\n",
        "    now = datetime.datetime.now(dateutil.tz.tzlocal())\n",
        "    timestamp = now.strftime('%Y_%m_%d_%H_%M_%S')\n",
        "    output_dir = '../output/%s_%s_%s' % \\\n",
        "        (cfg.DATASET_NAME, cfg.CONFIG_NAME, timestamp)\n",
        "\n",
        "    if cfg.CUDA:\n",
        "        torch.cuda.set_device(cfg.GPU_ID)\n",
        "        cudnn.benchmark = True\n",
        "\n",
        "    # Get data loader ##################################################\n",
        "    imsize = cfg.TREE.BASE_SIZE\n",
        "    batch_size = cfg.TRAIN.BATCH_SIZE\n",
        "    image_transform = transforms.Compose([\n",
        "        transforms.Resize(int(imsize * 76 / 64)),\n",
        "        transforms.RandomCrop(imsize),\n",
        "        transforms.RandomHorizontalFlip()])\n",
        "\n",
        "\n",
        "# Main area to work on      ###################################\n",
        "    dataset = TextDataset(cfg.DATA_DIR, 'test',\n",
        "                            base_size=cfg.TREE.BASE_SIZE,\n",
        "                            transform=image_transform)\n",
        "    print(dataset.n_words, dataset.embeddings_num)\n",
        "    assert dataset\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=batch_size, drop_last=True,\n",
        "        shuffle=True, num_workers=int(cfg.WORKERS))\n",
        "\n",
        "###############################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    netG = NetG(cfg.TRAIN.NF, 100).to(device)\n",
        "    netD = NetD(cfg.TRAIN.NF).to(device)\n",
        "\n",
        "    text_encoder = RNN_ENCODER(dataset.n_words, nhidden=cfg.TEXT.EMBEDDING_DIM)\n",
        "    state_dict = torch.load(cfg.TEXT.DAMSM_NAME, map_location=lambda storage, loc: storage)\n",
        "    text_encoder.load_state_dict(state_dict)\n",
        "    text_encoder.cuda()\n",
        "\n",
        "    for p in text_encoder.parameters():\n",
        "        p.requires_grad = False\n",
        "    text_encoder.eval()\n",
        "\n",
        "\n",
        "initialize()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-9230ac041173>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    from DF-GAN.code.miscc.config import cfg, cfg_from_file\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}